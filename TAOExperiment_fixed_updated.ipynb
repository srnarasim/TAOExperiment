{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a0lBEa5262Y"
   },
   "source": [
    "# TAO Experiment - Text Classification with Test-time Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a CSV file with sample content\n",
    "\n",
    "import csv\n",
    "\n",
    "data = [\n",
    "    ['Product', 'Product Description', 'Category'],\n",
    "    ['Wireless Bluetooth headphones with noise cancellation', 'Headphones', 'Electronics'],\n",
    "    ['Smartphone with OLED display and 128GB storage', 'Smartphone', 'Electronics'],\n",
    "    ['Gaming laptop with high refresh rate screen', 'Laptop', 'Electronics'],\n",
    "    ['Smart home security camera with night vision', 'Smart Home Device', 'Electronics'],\n",
    "    ['Cotton t-shirt with graphic print design', 'T-shirt', 'Clothing'],\n",
    "    ['Wooden dining table with six matching chairs', 'Dining Table', 'Furniture'],\n",
    "    ['Genuine leather wallet with multiple card slots', 'Wallet', 'Accessories'],\n",
    "    ['Insulated stainless steel water bottle', 'Water Bottle', 'Kitchen']\n",
    "]\n",
    "\n",
    "with open('balanced_data.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(data)\n",
    "\n",
    "!cat balanced_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install datasets transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"balanced_data.csv\")\n",
    "\n",
    "# Load tokenizer (using BERT model)\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Create category mapping\n",
    "category_mapping = {category: idx for idx, category in enumerate(df[\"Category\"].unique())}\n",
    "df[\"Label\"] = df[\"Category\"].map(category_mapping)\n",
    "\n",
    "# Tokenize product descriptions\n",
    "max_length = 128\n",
    "encoded_data = tokenizer(\n",
    "    df[\"Product Description\"].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Store tokenized data in DataFrame\n",
    "df[\"input_ids\"] = encoded_data[\"input_ids\"].tolist()\n",
    "df[\"attention_mask\"] = encoded_data[\"attention_mask\"].tolist()\n",
    "\n",
    "print(\"Tokenization completed. DataFrame columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Create dataset\n",
    "dataset_dict = {\n",
    "    'input_ids': encoded_data['input_ids'].numpy(),\n",
    "    'attention_mask': encoded_data['attention_mask'].numpy(),\n",
    "    'labels': df['Label'].values\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(dataset_dict)\n",
    "train_test = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Initialize model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(category_mapping)\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_test[\"train\"],\n",
    "    eval_dataset=train_test[\"test\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-time Adaptation for New Categories\n",
    "This section implements test-time adaptation to detect products from new, unseen categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def predict_product_category(text, entropy_threshold=1.5, confidence_threshold=0.4):\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    \n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Convert to probabilities using softmax\n",
    "        probabilities = F.softmax(logits, dim=-1).cpu().numpy()[0]\n",
    "        \n",
    "        # Calculate entropy\n",
    "        entropy = -np.sum(probabilities * np.log(probabilities + 1e-9))\n",
    "        \n",
    "        # Calculate confidence\n",
    "        confidence = np.max(probabilities)\n",
    "        \n",
    "        # Make prediction\n",
    "        if entropy > entropy_threshold or confidence < confidence_threshold:\n",
    "            print(f\"Product '{text}' might be a NEW category!\")\n",
    "            print(f\"Entropy: {entropy:.3f}, Confidence: {confidence:.3f}\")\n",
    "            return 'New Category'\n",
    "        else:\n",
    "            predicted_idx = np.argmax(probabilities)\n",
    "            category = list(category_mapping.keys())[predicted_idx]\n",
    "            print(f\"Product '{text}' classified as: {category}\")\n",
    "            print(f\"Confidence: {confidence:.3f}, Entropy: {entropy:.3f}\")\n",
    "            return category\n",
    "\n",
    "# Test with various product descriptions\n",
    "test_products = [\n",
    "    # Known categories\n",
    "    \"Wireless gaming headphones with RGB lighting\",\n",
    "    \"Wooden dining table with extendable leaf\",\n",
    "    \"Classic leather wallet with coin pocket\",\n",
    "    \"Cotton polo shirt with embroidered logo\",\n",
    "    \n",
    "    # Potentially new categories\n",
    "    \"Smart fitness tracker with heart rate monitor\",\n",
    "    \"Electric scooter with foldable design\",\n",
    "    \"Organic green tea from Japan\",\n",
    "    \"Professional oil painting set with easel\",\n",
    "    \"Garden tools set with pruning shears\",\n",
    "    \"Yoga mat with alignment lines\"\n",
    "]\n",
    "\n",
    "print(\"Testing product classification with test-time adaptation:\\n\")\n",
    "results = []\n",
    "for product in test_products:\n",
    "    category = predict_product_category(product)\n",
    "    results.append({'Product': product, 'Predicted Category': category})\n",
    "    print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "# Display results in a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}